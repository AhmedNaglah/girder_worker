# it is not really python, but there is no R support on Travis CI yet
language: python

sudo: false

addons:
  apt:
    packages:
      - python-virtualenv
      - gfortran
      - openjdk-7-jdk

cache:
  directories:
    - $HOME/spark-1.3.1-bin-hadoop2.4
    - $HOME/scala-2.10.5
    - $HOME/local
    - $HOME/swift-0.96.1

# environment variables
env:
  - PYTHONPATH=~/vtk-precise64/lib/python2.7/site-packages:~/vtk-precise64/lib LD_LIBRARY_PATH=~/vtk-precise64/lib:~/local/lib:~/local/lib/R/lib

before_install:
  - pushd "${HOME}"
  - curl "https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-${MONGO_VERSION}.tgz" | gunzip -c | tar x
  - cd mongodb-*/bin && export PATH="${PWD}:${PATH}"
  - popd
  - mkdir /tmp/db
  - mongod --dbpath=/tmp/db >/dev/null 2>/dev/null &
  - mongod --version
  - pushd "${HOME}"
  - curl -L "http://cmake.org/files/v3.2/cmake-3.2.2-Linux-x86_64.tar.gz" | gunzip -c | tar x
  - cd cmake-*/bin && export PATH="${PWD}:${PATH}"
  - popd
  - cmake --version
  # download VTK
  - curl -L http://midas3.kitware.com/midas/download/bitstream/366970/vtk-precise64-118242.tar.gz | tar zx -C ~
  # install R
  - mkdir -p $HOME/local
  - if [ ! -f $HOME/local/env-R ] ; then curl -L http://midas3.kitware.com/midas/download/bitstream/457205/R_3.2.0.tar.bz2 | tar jx -C $HOME/local/ ; mv $HOME/local/env $HOME/local/env-R ; fi
  - source $HOME/local/env-R
  - if [ ! -f $HOME/local/env-arbor ] ; then curl -L http://midas3.kitware.com/midas/download/bitstream/457206/aRbor-packages_1.0.0.tar.bz2 | tar jx -C $HOME/local/ ; mv $HOME/local/env $HOME/local/env-arbor ; fi
  - source $HOME/local/env-arbor
  - R --version
  - R -e '.libPaths(); sessionInfo()'
  # install spark
  - export SCALA_HOME=$HOME/scala-2.10.5
  - if [ ! -d $SCALA_HOME ] ; then curl -L http://www.scala-lang.org/files/archive/scala-2.10.5.tgz | tar zx -C ~ ; fi
  - export PATH=$PATH:$SCALA_HOME/bin
  - scala -version
  - export SPARK_HOME=$HOME/spark-1.3.1-bin-hadoop2.4
  - export SPARK_MASTER_IP=localhost
  - if [ ! -f $SPARK_HOME/sbin/start-master.sh ] ; then curl -L https://www.apache.org/dist/spark/spark-1.3.1/spark-1.3.1-bin-hadoop2.4.tgz | tar -zx -C ~ ; fi
  - $SPARK_HOME/sbin/start-master.sh
  - sleep 3
  - $SPARK_HOME/sbin/start-slave.sh worker1 spark://localhost:7077
  # install swift
  - export PATH=$PATH:$HOME/swift-0.96.1/bin
  - swift --version || curl -L http://swiftlang.org/packages/swift-0.96.1.tar.gz | tar zx -C ~
  - swift --version

# install dependencies
install:
  # install Python packages for core and all plugins
  - python scripts/install_requirements.py --mode=dev --all

# run tests
script:
  - mkdir _build
  - cd _build
  - cmake -D PYTHON_COVERAGE:BOOL=ON -D SPARK_TEST_MASTER_URL:STRING="spark://localhost:7077" ..
  - ctest -VV -S ../cmake/travis_continuous.cmake || true
  - if [ -f test_failed ] ; then false ; fi
  - cd ..

after_success:
  - coveralls
