# it is not really Python, but there is no R support on Travis CI yet
language: python

sudo: false

services:
  - docker

addons:
  apt:
    packages:
      - python-virtualenv
      - gfortran
      - openjdk-7-jdk

cache:
  directories:
    - $HOME/spark-1.3.1-bin-hadoop2.4
    - $HOME/scala-2.10.5
    - $HOME/local
    - $HOME/swift-0.96.1
    - $HOME/julia-0.4.2

# environment variables
env:
  - PYTHONPATH=~/vtk-precise64/lib/python2.7/site-packages:~/vtk-precise64/lib LD_LIBRARY_PATH=~/vtk-precise64/lib:~/local/lib:~/local/lib/R/lib

before_install:
  - pip install -U pip six
  - pushd "${HOME}"
  - curl "https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-${MONGO_VERSION}.tgz" | gunzip -c | tar x
  - cd mongodb-*/bin && export PATH="${PWD}:${PATH}"
  - popd
  - mkdir /tmp/db
  - mongod --dbpath=/tmp/db >/dev/null 2>/dev/null &
  - mongod --version
  - pushd "${HOME}"
  - curl -L "http://cmake.org/files/v3.2/cmake-3.2.2-Linux-x86_64.tar.gz" | gunzip -c | tar x
  - cd cmake-*/bin && export PATH="${PWD}:${PATH}"
  - popd
  - cmake --version
  # download VTK
  - curl -L http://midas3.kitware.com/midas/download/bitstream/366970/vtk-precise64-118242.tar.gz | tar zx -C ~
  # install R
  -  mkdir -p $HOME/local
  - if [ ! -f $HOME/local/env-arbor ] ; then curl -L https://data.kitware.com/api/v1/file/588b63c68d777f4f3f30c776/download | tar jx -C $HOME/local/ ; mv $HOME/local/env $HOME/local/env-arbor ; fi
  - source $HOME/local/env-arbor
  - R --version
  - R -e '.libPaths(); sessionInfo()'
  # install spark
  - export SCALA_HOME=$HOME/scala-2.10.5
  - if [ ! -d $SCALA_HOME/bin ] ; then curl -L http://www.scala-lang.org/files/archive/scala-2.10.5.tgz | tar zx -C ~ ; fi
  - export PATH=$PATH:$SCALA_HOME/bin
  - which scala
  - export SPARK_HOME=$HOME/spark-1.3.1-bin-hadoop2.4
  - export SPARK_MASTER_IP=localhost
  - if [ ! -f $SPARK_HOME/sbin/start-master.sh ] ; then curl -L https://archive.apache.org/dist/spark/spark-1.3.1/spark-1.3.1-bin-hadoop2.4.tgz | tar -zx -C ~ ; fi
  - export PATH=$PATH:$SPARK_HOME/bin
  - which spark-shell
  - $SPARK_HOME/sbin/start-master.sh
  - sleep 3
  - $SPARK_HOME/sbin/start-slave.sh worker1 spark://localhost:7077
  # install swift
  - export PATH=$PATH:$HOME/swift-0.96.1/bin
  - swift --version || curl -L http://swiftlang.org/packages/swift-0.96.1.tar.gz | tar zx -C ~
  - swift --version
  # install julia
  - export JULIA_INSTALL_HOME=$HOME/julia-0.4.2
  - export PATH=$PATH:$JULIA_INSTALL_HOME/bin
  - julia --version || mkdir -p $JULIA_INSTALL_HOME && curl https://julialang.s3.amazonaws.com/bin/linux/x64/0.4/julia-0.4.2-linux-x86_64.tar.gz | tar zx -C $JULIA_INSTALL_HOME --strip-components 1
  - julia --version

# install dependencies
install:
  # install Python packages for core and all plugins
  - python scripts/install_requirements.py --mode=dev --all

# run tests
script:
  - mkdir _build
  - cd _build
  - cmake -D PYTHON_COVERAGE:BOOL=ON -D SPARK_TEST_MASTER_URL:STRING="spark://localhost:7077" ..
  - ctest -VV -S ../cmake/travis_continuous.cmake || true
  - if [ -f test_failed ] ; then false ; fi
  - cd ..

after_success:
  - coveralls
